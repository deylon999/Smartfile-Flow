import json
import os
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from logger import get_logger
from config import get_config
from ml_model import MLClassifier

class FileSorter:
    def __init__(self, source_dir: str, target_dir: str):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.logger = get_logger()
        self.config = get_config()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.ml_classifier = MLClassifier(use_pretrained=True)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é ML –º–æ–¥–µ–ª—å
        self._load_ml_model()
        
        self._create_category_folders()
    
    def _load_ml_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç ML –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –∏ –≤–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ"""
        if self.config.settings.use_ml:
            if not self.ml_classifier.load_model():
                self.logger.warning("ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è rule-based –ø–æ–¥—Ö–æ–¥")
    
    def _create_category_folders(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        self.target_dir.mkdir(parents=True, exist_ok=True)
        for category_name in self.config.get_category_names():
            category_path = self.target_dir / category_name
            category_path.mkdir(parents=True, exist_ok=True)
    
    def _read_text_with_encoding(self, file_path: Path) -> Optional[str]:
        """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª, –æ–ø—Ä–µ–¥–µ–ª—è—è –∫–æ–¥–∏—Ä–æ–≤–∫—É"""
        try:
            import chardet
            with open(file_path, 'rb') as f:
                raw_data = f.read()
        except FileNotFoundError:
            self.logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return None
        except OSError as exc:
            self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {exc}")
            return None
        
        if not raw_data:
            return ""
        
        encoding = chardet.detect(raw_data).get('encoding') or 'utf-8'
        try:
            return raw_data.decode(encoding, errors='ignore')
        except LookupError:
            self.logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ '{encoding}' –¥–ª—è {file_path}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UTF-8")
            return raw_data.decode('utf-8', errors='ignore')
    
    def _collect_json_text(self, data: Any, collector: List[str], depth: int = 0, max_depth: int = 32):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ JSON, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è –≥–ª—É–±–∏–Ω—É"""
        if depth > max_depth:
            return
        
        if isinstance(data, dict):
            for key, value in data.items():
                collector.append(str(key))
                self._collect_json_text(value, collector, depth + 1, max_depth)
        elif isinstance(data, (list, tuple, set)):
            for item in data:
                self._collect_json_text(item, collector, depth + 1, max_depth)
        elif data is None:
            return
        else:
            collector.append(str(data))
    
    def _extract_text_from_json(self, file_path: Path) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        decoded_text = self._read_text_with_encoding(file_path)
        if decoded_text is None:
            return None
        if not decoded_text.strip():
            return ""
        
        try:
            payload = json.loads(decoded_text)
        except json.JSONDecodeError as exc:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON {file_path}: {exc}")
            return None
        
        collected: List[str] = []
        self._collect_json_text(payload, collected)
        return " ".join(collected).strip()
    
    def _extract_text_from_xml(self, file_path: Path) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ XML —Ñ–∞–π–ª–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º"""
        try:
            from defusedxml import ElementTree as ET
            parser_name = "defusedxml"
        except ImportError:
            import xml.etree.ElementTree as ET
            parser_name = "xml.etree"
            self.logger.warning("defusedxml –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π XML-–ø–∞—Ä—Å–µ—Ä")
        
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
        except (ET.ParseError, OSError) as exc:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ XML {file_path}: {exc}")
            return None
        
        if root is None:
            self.logger.debug(f"XML —Ñ–∞–π–ª {file_path} ({parser_name}): –∫–æ—Ä–Ω–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            return ""
        
        fragments: List[str] = []
        for elem in list(root.iter()):
            if elem.text and elem.text.strip():
                fragments.append(elem.text.strip())
            for attr_val in elem.attrib.values():
                if attr_val:
                    fragments.append(str(attr_val))
            if elem.tail and elem.tail.strip():
                fragments.append(elem.tail.strip())
        
        if not fragments:
            self.logger.debug(f"XML —Ñ–∞–π–ª {file_path} ({parser_name}) –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
        return " ".join(fragments).strip()
    
    def extract_text_from_file(self, file_path: Path) -> Optional[str]:
        try:
            file_ext = file_path.suffix.lower()
            
            if file_ext == '.txt':
                return self._read_text_with_encoding(file_path)
                    
            elif file_ext == '.pdf':
                try:
                    import pdfplumber
                    text = ""
                    with pdfplumber.open(file_path) as pdf:
                        for page in pdf.pages:
                            page_text = page.extract_text()
                            if page_text:
                                text += page_text + " "
                    return text.strip()
                except ImportError:
                    self.logger.warning("pdfplumber –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PyPDF2")
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ' '.join([page.extract_text() for page in reader.pages if page.extract_text()])
                    return text
                    
            elif file_ext in ['.docx', '.doc']:
                import docx
                doc = docx.Document(str(file_path))
                text = ' '.join([paragraph.text for paragraph in doc.paragraphs])
                return text
            
            elif file_ext == '.json':
                return self._extract_text_from_json(file_path)
            
            elif file_ext == '.xml':
                return self._extract_text_from_xml(file_path)
                
            else:
                self.logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_ext}")
                return None
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None
    
    def categorize_with_rules(self, text: str) -> Tuple[str, float]:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª (–≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)"""
        if not text:
            return 'other', 0.0
        
        text_lower = text.lower()
        category_scores: Dict[str, float] = {}
        
        for category_name in self.config.get_category_names():
            if category_name == 'other':
                continue
                
            weighted_keywords = self.config.get_weighted_keywords(category_name)
            score = 0.0
            
            for keyword, weight in weighted_keywords:
                count = text_lower.count(keyword)
                score += count * weight
                
                # –ë–æ–Ω—É—Å –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
                if count > 1:
                    score += count * 0.2
            
            if score >= self.config.settings.min_confidence_score:
                category_scores[category_name] = score
        
        if category_scores:
            best_category = max(category_scores.keys(), key=lambda k: category_scores[k])
            confidence = category_scores[best_category]
            return best_category, confidence
        
        return 'other', 0.0
    
    def categorize_with_ml(self, text: str) -> Tuple[str, float]:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML"""
        if not self.config.settings.use_ml or not self.ml_classifier.is_trained:
            return self.categorize_with_rules(text)
        
        category, confidence = self.ml_classifier.predict_category(text)
        
        if category and confidence >= self.config.settings.ml_confidence_threshold:
            return category, confidence
        else:
            # Fallback –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –µ—Å–ª–∏ ML –Ω–µ —É–≤–µ—Ä–µ–Ω
            return self.categorize_with_rules(text)
    
    def categorize_file(self, text: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        if self.config.settings.use_ml and self.ml_classifier.is_trained:
            category, confidence = self.categorize_with_ml(text)
            method = "ML"
            # –î–ª—è ML: –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –æ—Ç 0 –¥–æ 1
            if confidence > 0.8:
                self.logger.info(f"üéØ {category}: –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2f} ({method})")
            elif confidence > 0.5:
                self.logger.info(f"‚úÖ {category}: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2f} ({method})")
            elif confidence >= self.config.settings.ml_confidence_threshold:
                self.logger.info(f"ü§î {category}: –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2f} ({method})")
            else:
                self.logger.info(f"‚ö†Ô∏è {category}: –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2f} ({method})")
        else:
            category, confidence = self.categorize_with_rules(text)
            method = "–ø—Ä–∞–≤–∏–ª–∞"
            # –î–ª—è –ø—Ä–∞–≤–∏–ª: score –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ 1.0
            if confidence > 5.0:
                self.logger.info(f"üéØ {category}: –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1f} ({method})")
            elif confidence > 2.0:
                self.logger.info(f"‚úÖ {category}: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1f} ({method})")
            else:
                self.logger.info(f"ü§î {category}: –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1f} ({method})")
        
        return category
    
    def scan_directory(self) -> List[Path]:
        files = []
        
        if not self.source_dir.exists():
            self.logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.source_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            return files
        
        for ext in self.config.settings.supported_extensions:
            for file_path in self.source_dir.glob(f"*{ext}"):
                if file_path.is_file():
                    files.append(file_path)
        
        return files
    
    def _log_with_tqdm(self, message: str, level: str = 'info'):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π tqdm"""
        try:
            from tqdm import tqdm
            instances = getattr(tqdm, "_instances", None)
            if instances is not None and len(instances) > 0:
                tqdm.write(message)
                # –¢–∞–∫–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ –æ–±—ã—á–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è —Ñ–∞–π–ª–∞
                if level == 'warning':
                    self.logger.warning(message)
                elif level == 'error':
                    self.logger.error(message)
                else:
                    self.logger.info(message)
            else:
                if level == 'warning':
                    self.logger.warning(message)
                elif level == 'error':
                    self.logger.error(message)
                else:
                    self.logger.info(message)
        except (ImportError, AttributeError):
            if level == 'warning':
                self.logger.warning(message)
            elif level == 'error':
                self.logger.error(message)
            else:
                self.logger.info(message)
    
    def _resolve_conflict(self, target_path: Path) -> Tuple[Path, bool]:
        """
        –†–∞–∑—Ä–µ—à–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ conflict_resolution
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª)
        """
        if not target_path.exists():
            return target_path, True
        
        resolution = self.config.settings.conflict_resolution
        
        if resolution == 'skip':
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª
            message = f"‚è≠Ô∏è  –§–∞–π–ª {target_path.name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (conflict_resolution=skip)"
            self._log_with_tqdm(message, level='warning')
            return target_path, False
        
        elif resolution == 'overwrite':
            # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º
            message = f"‚ö†Ô∏è  –§–∞–π–ª {target_path.name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º (conflict_resolution=overwrite)"
            self._log_with_tqdm(message, level='warning')
            return target_path, True
        
        elif resolution == 'rename':
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º
            stem = target_path.stem
            suffix = target_path.suffix
            parent = target_path.parent
            
            counter = 1
            while True:
                new_name = f"{stem}_{counter}{suffix}"
                new_path = parent / new_name
                if not new_path.exists():
                    message = f"üìù –§–∞–π–ª –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω: {target_path.name} -> {new_name} (–¥—É–±–ª–∏–∫–∞—Ç)"
                    self._log_with_tqdm(message, level='info')
                    return new_path, True
                counter += 1
        
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º rename –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.logger.warning(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ '{resolution}', –∏—Å–ø–æ–ª—å–∑—É–µ–º 'rename'")
            return self._resolve_conflict(target_path)  # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å rename
    
    def sort_file(self, file_path: Path) -> Optional[str]:
        """
        –°–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: 'sorted' - —É—Å–ø–µ—à–Ω–æ, 'skipped' - –ø—Ä–æ–ø—É—â–µ–Ω, None - –æ—à–∏–±–∫–∞
        """
        text = self.extract_text_from_file(file_path)
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
        if text is None or not text.strip():
            self._log_with_tqdm(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {file_path.name}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞", level='warning')
            category = 'other'
        else:
            category = self.categorize_file(text)
        
        target_path = self.target_dir / category / file_path.name
        
        # –†–∞–∑—Ä–µ—à–∞–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
        target_path, should_process = self._resolve_conflict(target_path)
        
        if not should_process:
            return 'skipped'  # –§–∞–π–ª –ø—Ä–æ–ø—É—â–µ–Ω
        
        try:
            if self.config.settings.copy_files:
                shutil.copy2(file_path, target_path)
                action = "—Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω"
            else:
                shutil.move(file_path, target_path)
                action = "–ø–µ—Ä–µ–º–µ—â–µ–Ω"
            
            color = self.config.get_category_color(category)
            self.logger.info(f"{color} {file_path.name} -> {category}/ ({action})")
            return 'sorted'
            
        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}"
            self._log_with_tqdm(error_msg, level='error')
            # –î–ª—è –æ—à–∏–±–æ–∫ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º logger.error
            self.logger.error(error_msg)
            return None
    
    def sort_all(self, show_progress: bool = True):
        """
        –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        
        Args:
            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        """
        self.logger.start_session(str(self.source_dir), str(self.target_dir))
        
        files = self.scan_directory()
        
        if not files:
            self.logger.warning("–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return {
                'total': 0,
                'sorted': 0,
                'failed': 0,
                'skipped': 0,
                'by_category': {},
                'method_used': 'none',
                'conflict_resolution': self.config.settings.conflict_resolution
            }
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")
        
        sorted_count = 0
        failed_count = 0
        skipped_count = 0
        by_category = {}
        ml_used = 0
        rules_used = 0
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        use_progress_bar = False
        try:
            if show_progress and len(files) > 1:
                from tqdm import tqdm
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm.write –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
                file_iterator = tqdm(files, desc="üìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞", unit="—Ñ–∞–π–ª", 
                                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {postfix}]',
                                    ncols=100, mininterval=0.5)
                use_progress_bar = True
            else:
                file_iterator = files
        except ImportError:
            # –ï—Å–ª–∏ tqdm –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∏—Ç–µ—Ä–∞—Ç–æ—Ä
            self.logger.debug("tqdm –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –æ—Ç–∫–ª—é—á–µ–Ω")
            file_iterator = files
            use_progress_bar = False
        
        # –Ø–≤–Ω–æ –≥–æ–≤–æ—Ä–∏–º —Ç–∏–ø–∏–∑–∞—Ç–æ—Ä—É, —á—Ç–æ –∫–æ–≥–¥–∞ use_progress_bar=True, —É –Ω–∞—Å –µ—Å—Ç—å tqdm-–æ–±—ä–µ–∫—Ç
        progress_bar = None
        try:
            from tqdm import tqdm  # type: ignore
            if use_progress_bar and isinstance(file_iterator, tqdm):
                progress_bar = file_iterator  # type: ignore[assignment]
        except ImportError:
            progress_bar = None

        for file_path in file_iterator:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–¥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è)
            text = self.extract_text_from_file(file_path)
            if text:
                category = self.categorize_file(text)
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥
                if self.config.settings.use_ml and self.ml_classifier.is_trained:
                    ml_used += 1
                else:
                    rules_used += 1
            else:
                category = 'other'
                rules_used += 1
            
            result = self.sort_file(file_path)
            if result == 'sorted':
                sorted_count += 1
                by_category[category] = by_category.get(category, 0) + 1
            elif result == 'skipped':
                skipped_count += 1
            else:
                failed_count += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            if progress_bar is not None:
                progress_bar.set_postfix({
                    '‚úÖ': sorted_count,
                    '‚è≠Ô∏è': skipped_count,
                    '‚ùå': failed_count
                })
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            'total': len(files),
            'sorted': sorted_count,
            'failed': failed_count,
            'skipped': skipped_count,
            'by_category': by_category,
            'method_used': 'ML' if ml_used > rules_used else 'rules' if rules_used > 0 else 'none',
            'ml_count': ml_used,
            'rules_count': rules_used,
            'conflict_resolution': self.config.settings.conflict_resolution
        }
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.logger.info("\n" + "=" * 50)
        self.logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–û–†–¢–ò–†–û–í–ö–ò")
        self.logger.info("=" * 50)
        self.logger.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total']}")
        self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {stats['sorted']}")
        if stats['skipped'] > 0:
            self.logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏–∫–∞—Ç—ã): {stats['skipped']}")
        if stats['failed'] > 0:
            self.logger.info(f"–û—à–∏–±–æ–∫: {stats['failed']}")
        self.logger.info(f"–ú–µ—Ç–æ–¥: {stats['method_used']} (ML: {stats['ml_count']}, –ø—Ä–∞–≤–∏–ª–∞: {stats['rules_count']})")
        self.logger.info(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤: {stats['conflict_resolution']}")
        if stats['by_category']:
            self.logger.info("\n–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category, count in sorted(stats['by_category'].items(), key=lambda x: x[1], reverse=True):
                color = self.config.get_category_color(category)
                self.logger.info(f"  {color} {category}: {count} —Ñ–∞–π–ª–æ–≤")
        self.logger.info("=" * 50)
        
        self.logger.end_session(sorted_count, len(files))
        
        return stats
    
    def train_ml_model(self, training_data: Dict[str, List[str]]) -> bool:
        """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        self.logger.info("üß† –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏...")
        
        success = self.ml_classifier.train_word2vec(training_data)
        
        if success:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            self.ml_classifier.save_model()
            self.logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        else:
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å ML –º–æ–¥–µ–ª—å")
        
        return success

def main():
    project_root = Path(__file__).parent.parent
    source_dir = project_root / 'data' / 'raw'
    target_dir = project_root / 'data' / 'sorted'
    
    source_dir.mkdir(parents=True, exist_ok=True)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    test_files = [
        ("—Ä–∞–±–æ—Ç–∞.txt", "–≠—Ç–æ –º–æ–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–µ–∫—Ç –∏ –∑–∞–¥–∞—á–∏ –Ω–∞ –Ω–µ–¥–µ–ª—é. –í—Å—Ç—Ä–µ—á–∞ —Å –∫–ª–∏–µ–Ω—Ç–æ–º –≤ –ø—è—Ç–Ω–∏—Ü—É."),
        ("—Ñ–∏–Ω–∞–Ω—Å—ã.txt", "–ë—é–¥–∂–µ—Ç —Å–µ–º—å–∏ –Ω–∞ –º–µ—Å—è—Ü, –æ–ø–ª–∞—Ç–∞ —Å—á–µ—Ç–æ–≤ –∑–∞ –±–∞–Ω–∫ –∏ –∑–∞—Ä–ø–ª–∞—Ç–∞."),
        ("–æ—Ç–ø—É—Å–∫.txt", "–ü–ª–∞–Ω—ã –Ω–∞ –æ—Ç–ø—É—Å–∫ —Å —Å–µ–º—å–µ–π –∏ –¥—Ä—É–∑—å—è–º–∏. –ü—Ä–∞–∑–¥–Ω–∏–∫ –≤ –∏—é–ª–µ."),
        ("—É—á–µ–±–∞.txt", "–õ–µ–∫—Ü–∏–∏ –ø–æ –∫—É—Ä—Å—É –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –∫ —ç–∫–∑–∞–º–µ–Ω—É.")
    ]
    
    for filename, content in test_files:
        file_path = source_dir / filename
        if not file_path.exists():
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
    
    sorter = FileSorter(str(source_dir), str(target_dir))
    sorter.sort_all()

if __name__ == '__main__':
    main()