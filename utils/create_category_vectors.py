"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ data/sorted/
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from file_sorter import FileSorter
from ml_model import MLClassifier
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

def collect_texts_from_sorted_files():
    """–°–æ–±–∏—Ä–∞–µ—Ç —Ç–µ–∫—Å—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ data/sorted/ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    print("=" * 70)
    print("üìö –°–ë–û–† –î–ê–¢–ê–°–ï–¢–ê –ò–ó –§–ê–ô–õ–û–í")
    print("=" * 70)
    
    project_root = Path(__file__).parent.parent
    sorted_dir = project_root / 'data' / 'sorted'
    
    if not sorted_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {sorted_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return {}
    
    # –°–æ–∑–¥–∞–µ–º FileSorter –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤
    sorter = FileSorter("data/raw", "data/sorted")
    
    # –ú–∞–ø–ø–∏–Ω–≥ –ø–∞–ø–æ–∫ –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_mapping = {
        'work': 'work',
        'finance': 'finance',
        'personal': 'personal',
        'study': 'study',
        'other': 'other'
    }
    
    training_data = {}
    
    print("\nüìÇ –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º...")
    
    for folder_name, category in category_mapping.items():
        category_dir = sorted_dir / folder_name
        
        if not category_dir.exists():
            print(f"   ‚ö†Ô∏è  –ü–∞–ø–∫–∞ {folder_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
        
        texts = []
        files = list(category_dir.glob('*'))
        
        print(f"\n   üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}' ({folder_name}/):")
        
        for file_path in files:
            if not file_path.is_file():
                continue
            
            print(f"      –ß–∏—Ç–∞—é: {file_path.name}...", end=' ')
            
            text = sorter.extract_text_from_file(file_path)
            
            if text and text.strip():
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ (–±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5000 —Å–∏–º–≤–æ–ª–æ–≤)
                text = text.strip()[:5000]
                texts.append(text)
                print(f"‚úÖ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                print("‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
        
        if texts:
            training_data[category] = texts
            print(f"   ‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")
        else:
            print(f"   ‚ö†Ô∏è  –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")
    
    print(f"\nüìä –ò–¢–û–ì–û:")
    total_texts = sum(len(texts) for texts in training_data.values())
    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(training_data)}")
    print(f"   –í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {total_texts}")
    for category, texts in training_data.items():
        print(f"   - {category}: {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
    
    return training_data

def create_category_vectors(training_data):
    """–°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("\n" + "=" * 70)
    print("üîß –°–û–ó–î–ê–ù–ò–ï –í–ï–ö–¢–û–†–û–í –ö–ê–¢–ï–ì–û–†–ò–ô")
    print("=" * 70)
    
    if not training_data:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤!")
        return False
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    print("\n1Ô∏è‚É£  –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    classifier = MLClassifier(use_pretrained=True)
    
    if not classifier.load_model():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å!")
        return False
    
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    print("\n2Ô∏è‚É£  –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    classifier._create_category_vectors(training_data)
    
    if not classifier.category_vectors:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π!")
        return False
    
    print(f"\n‚úÖ –í–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω—ã:")
    for category, vector in classifier.category_vectors.items():
        print(f"   - {category}: —Ä–∞–∑–º–µ—Ä {len(vector)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã
    print("\n3Ô∏è‚É£  –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    if classifier.save_model():
        print("‚úÖ –í–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
        return True
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤!")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –®–∞–≥ 1: –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤
    training_data = collect_texts_from_sorted_files()
    
    if not training_data:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤!")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ data/sorted/ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        return
    
    # –®–∞–≥ 2: –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    success = create_category_vectors(training_data)
    
    if success:
        print("\n" + "=" * 70)
        print("‚úÖ –í–°–ï –ì–û–¢–û–í–û!")
        print("=" * 70)
        print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   1. –í–∫–ª—é—á–∏—Ç–µ ML –≤ config.yaml: use_ml: true")
        print("   2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–æ–≤")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π!")

if __name__ == '__main__':
    main()

